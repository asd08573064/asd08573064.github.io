---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

 ðŸ‘‹ My name is Hao-Wei, I am a research assistant at National [Tsing Hua University](https://nthu-en.site.nthu.edu.tw/) at [Theta Lab](http://theta.cs.nthu.edu.tw/) advices by Prof. **Yiyu Shi** at the [Unversity of Notre Dame](https://www.nd.edu/).  During my B.S study, I interned at AMD and Point Robotics. My primary areas of interest in research are AI fairness and computer vision ðŸ‘€ in medical field. Currently, I am conducting research on AI Fairness on dermatological task and submitted my first co-author paper about AI fairness to ICLR2023. I plan to extend my work to a unsupervised manner (without any sensitive attributes). Also, right now, I am applying for M.S. and Phd programs in Computer Science in the U.S. Feel free to contact me if you have any questions!
 
 
Projects
======
TestTestTestTestTestTestTestTest

Recommanding Sysyem
------
TestTestTestTestTestTest

Vending Machine
------
TestTestTestTestTest

Publications
======

Representative Image Feature Extraction via Contrastive Learning Pretraining for Chest X-ray Report Generation
------
Chen, Yu-Jen, et al. "Representative Image Feature Extraction via Contrastive Learning Pretraining for Chest X-ray Report Generation." arXiv preprint arXiv:2209.01604 (2022).

### Abstract
Medical report generation is a challenging task since it is time-consuming and requires expertise from experienced radiologists. The goal of medical report generation is to accurately capture and describe the image findings. Previous works pretrain their visual encoding neural networks with large datasets in different domains, which cannot learn general visual representation in the specific medical domain. In this work, we propose a medical report generation framework that uses a contrastive learning approach to pretrain the visual encoder and requires no additional meta information. In addition, we adopt lung segmentation as an augmentation method in the contrastive learning framework. This segmentation guides the network to focus on encoding the visual feature within the lung region. Experimental results show that the proposed framework improves the performance and the quality of the generated medical reports both quantitatively and qualitatively.

[Download paper here](https://arxiv.org/pdf/2209.01604.pdf)
